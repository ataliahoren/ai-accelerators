# Deploy Scoring Code as a microservice

**Author:** Pavel Ustinov

**Date:** June 26th, 2023

## Problem framing

[Scoring Code](https://docs.datarobot.com/en/docs/predictions/port-pred/scoring-code/sc-overview.html) allows you to export DataRobot models as [JAR files](https://docs.datarobot.com/en/docs/predictions/port-pred/scoring-code/sc-jar-integrations.html#scoring-code-jar-integrations) that can be used outside of the platform. You can do so without the need to introduce an additional level of customization on top of the model, while respecting company compliance requirements. Alternatively, you can embed the model into a low-latency application. 

There are multiple options on how to use exported Scoring Code for the inference: it can be used 
* On the [command line](https://docs.datarobot.com/en/docs/predictions/port-pred/scoring-code/scoring-cli.html) 
* Integrated with [Amazon SageMaker](https://docs.datarobot.com/en/docs/more-info/how-to/aws/sagemaker/sc-sagemaker.html)
* Integrated with [Apache Spark](https://docs.datarobot.com/en/docs/more-info/how-to/sc-apache-spark.html)
* Integrated with [Snowflake](https://docs.datarobot.com/en/docs/more-info/how-to/snowflake/snowflake-sc.html)
* Embedded into an [existing Java project](https://docs.datarobot.com/en/docs/predictions/port-pred/scoring-code/quickstart-api.html#java-api-example)

This AI Accelerator explains the step-by-step procedure to embed Scoring Code in a microservice and prepare it as the Docker container for a deployment on customer infrastructure (it can be self- or hyperscaler-managed K8s). The [Micronaut framework](https://micronaut.io/download/) is used for the implementation as it is modular, efficient, and easy to use. Deployment is out of scope for this accelerator.

## Accelerator overview

This accelerator requires:

- The Maven project (the example is provided in this repository).
- Scoring JAR of the model trained and exported from DataRobot.
- A CSV file with scoring data for testing purposes.

The following steps outline the accelerator workflow.

1. Download Scoring Code from the DataRobot [Leaderboard](https://docs.datarobot.com/en/docs/predictions/port-pred/scoring-code/sc-download-leaderboard.html) or from a [deployment](https://docs.datarobot.com/en/docs/predictions/port-pred/scoring-code/sc-download-deployment.html).

2. Install the [Micronaut framework](https://micronaut.io/download/).

3. [Create an app](https://guides.micronaut.io/latest/creating-your-first-micronaut-app-maven-java.html) using the following command: 

    `mn create-app com.datarobot.micronaut.scoring --build=maven --lang=java`

4. Implement test and controller classes (see the attached Maven project that is ready to be used).

5. [Generate Docker](https://guides.micronaut.io/latest/micronaut-docker-image-maven-java.html) or an [executable JAR file](https://guides.micronaut.io/latest/executable-jar-maven-java.html) with Micronaut.

6. Create the folder that contains scoring file JAR downloaded in step 1.

7. Run Docker container with the following command: 

    `docker run -it --rm -p 8080:8080 -e MODEL_FOLDER=home --name scoring-container -v /Users/pavel.ustinov/Documents/customers/micronaut-scoring/scoring/model:/home scoring`

The environment variable `MODEL_FOLDER` points to the directory inside the Docker container (`home` directory in this example) that contains the scoring JAR. If its value is not provided, the default directory `model` will be used.

The mounted directory `-v /Users/pavel.ustinov/Documents/customers/micronaut-scoring/scoring/model:/home` should referenced to the local directory (`/Users/pavel.ustinov/Documents/customers/micronaut-scoring/scoring/model` in this example) that contains the scoring JAR.

8. Send data for inference using curl or Postman using the following command:

    `curl --location 'http://localhost:8080/score' --header 'Content-Type: text/plain' --data '@/Users/pavel.ustinov/Downloads/for_predictions100.csv'`

## Code structure

This is a classical Maven project with a `pom.xml` file generated by Micronaut in step 3.

There are five main files in the project: 

* `pom.xml`: a description of the Java project and its dependencies.
* `Application.java`
* `Predictions.java`
* `ScoringController.java`
* `ScoringControllerTest.java`

### pom.xml
This file is a description of the Java project and its dependencies.

### Application.java
This file is an entry point of the application.

### Predictions.java
This file is a class used to create the object that contains predictions.

### ScoringController.java
This file is a controller class that exposes the `/score` endpoint of the microservice. It contains 4 methods:

    - `public Predictions score(@Body String body) throws Exception {...}`
    This method reads the body of the incoming HTTP request, loads scoring JAR into the memory, and triggers scoring.
    
    - `private List<Map<String, Object>> readCsv(String body) {...}`
    This method deserializes the HTTP body and saves it into internal data structure.
    
    - `private void loadModel() throws Exception {...}`
    This method loads the JAR file with the model into RAM.
    
    - `private List<Double> makePredictions(List<Map<String, Object>> rowsToScore) {...}`
    This method runs inference itself.

### ScoringControllerTest.java

This file is a unit test that runs the local `HttpClient` in order to test the end-to-end process.
