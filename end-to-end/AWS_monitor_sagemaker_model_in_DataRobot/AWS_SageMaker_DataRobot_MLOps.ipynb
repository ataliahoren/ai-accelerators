{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate Amazon SageMaker with DataRobot MLOps\n",
    "\n",
    "Authors: Oleksandr Saienko, DataRobot\n",
    "Mao Shun, AWS\n",
    "\n",
    "Version 1.3 (04/03/2022)\n",
    "\n",
    "With Amazon SageMaker, you can package your own algorithms that can than be trained and deployed in the SageMaker environment. [DataRobot MLOps](https://docs.datarobot.com/en/docs/mlops/index.html) monitoring provides service health, data drift, accuracy monitoring, reports, and alerts about machine learning performance. This notebook is modified based on a [SageMaker example notebook](https://github.com/aws/amazon-sagemaker-examples/blob/main/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb) to show integration capabilities of DataRobot MLOps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To integrate with SageMaker, you must first build and register a SageMaker container.\n",
    "\n",
    "The README demonstrates how to build a custom SageMaker container in your local environment by including custom Python libraries for both training and inference. The README also includes DataRobot-related libraries useful for model monitoring.\n",
    "\n",
    "Additionally, modify the Dockerfile as you need and follow the command instructions.\n",
    "\n",
    "Once you have your container packaged, you can use it to train models and use the model for hosting.\n",
    "\n",
    "DataRobot recommends running the cells below in a SageMaker notebook instance for simplicity. If you want to run it locally, some settings need be added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Specify a bucket to use and the role used when working with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::293058073847:role/service-role/AmazonSageMaker-ExecutionRole-20220606T111248\n"
     ]
    }
   ],
   "source": [
    "# S3 prefix\n",
    "prefix = \"DEMO-scikit-byo-iris-v3\"\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a session\n",
    "\n",
    "The session remembers your connection parameters to SageMaker. Use it to perform all of the SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data\n",
    "\n",
    "This example workflow uses the [Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) and is included in the notebook folder.\n",
    "\n",
    "Use the tools provided by the SageMaker Python SDK to upload the data to a default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = \"data\"\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use SageMaker to fit your algorithm, create an `Estimator` that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constructed in the shell commands above.\n",
    "* The __role__. Defined above.\n",
    "* The __instance count__ is the number of machines to use for training.\n",
    "* The __instance type__ is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact is written.\n",
    "* The __session__ is the SageMaker session object that you defined above.\n",
    "\n",
    "Use fit() on the estimator to train against the data uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293058073847.dkr.ecr.us-east-1.amazonaws.com/sagemaker-datarobot-decision-trees:latest\n",
      "data_location\n",
      "s3://sagemaker-us-east-1-293058073847/DEMO-scikit-byo-iris-v3\n",
      "2023-03-23 10:54:00 Starting - Starting the training job...\n",
      "2023-03-23 10:54:24 Starting - Preparing the instances for trainingProfilerReport-1679568840: InProgress\n",
      "......\n",
      "2023-03-23 10:55:24 Downloading - Downloading input data..\u001B[34mStarting the training.\u001B[0m\n",
      "\u001B[34mTraining complete.\u001B[0m\n",
      "\n",
      "2023-03-23 10:55:52 Training - Training image download completed. Training in progress.\n",
      "2023-03-23 10:55:52 Uploading - Uploading generated training model\n",
      "2023-03-23 10:55:52 Completed - Training job completed\n",
      "Training seconds: 37\n",
      "Billable seconds: 37\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-datarobot-decision-trees:latest\".format(account, region)\n",
    "\n",
    "print(image)\n",
    "\n",
    "print(\"data_location\")\n",
    "print(data_location)\n",
    "\n",
    "tree = sage.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    1,\n",
    "    \"ml.c4.2xlarge\",\n",
    "    output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "tree.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure DataRobot MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the workflow, install a pip package in the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: datarobot-mlops in /opt/conda/lib/python3.7/site-packages (8.2.10)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops) (2.8.2)\n",
      "Requirement already satisfied: orjson>=3 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops) (3.8.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops) (1.3.5)\n",
      "Requirement already satisfied: future>=0.16 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops) (0.18.2)\n",
      "Requirement already satisfied: py4j<1,>=0.10.9.1 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops) (0.10.9.7)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datarobot-mlops) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datarobot-mlops) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil->datarobot-mlops) (1.14.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: datarobot-mlops-connected-client in /opt/conda/lib/python3.7/site-packages (8.2.10)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops-connected-client) (1.3.5)\n",
      "Requirement already satisfied: datarobot-mlops>=7.1 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops-connected-client) (8.2.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops-connected-client) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops-connected-client) (3.8.3)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (2.8.2)\n",
      "Requirement already satisfied: orjson>=3 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (3.8.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (6.0)\n",
      "Requirement already satisfied: future>=0.16 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.18.2)\n",
      "Requirement already satisfied: py4j<1,>=0.10.9.1 in /opt/conda/lib/python3.7/site-packages (from datarobot-mlops>=7.1->datarobot-mlops-connected-client) (0.10.9.7)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (4.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (6.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datarobot-mlops-connected-client) (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datarobot-mlops-connected-client) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datarobot-mlops-connected-client) (2019.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->datarobot-mlops-connected-client) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->datarobot-mlops-connected-client) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->datarobot-mlops-connected-client) (1.26.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil->datarobot-mlops>=7.1->datarobot-mlops-connected-client) (1.14.0)\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n",
      "\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.0.1\u001B[0m\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#installing DataRobot MLOps client\n",
    "!{sys.executable} -m pip install datarobot-mlops\n",
    "\n",
    "#installing mlops-cli tool\n",
    "!{sys.executable} -m pip install datarobot-mlops-connected-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DataRobot\n",
    "\n",
    "To use the DataRobot API, you first need to [create an API key](https://docs.datarobot.com/en/docs/api/api-quickstart/index.html#create-a-datarobot-api-key).\n",
    "\n",
    "Then, add `MLOPS_SERVICE_URL` and `MLOPS_API_TOKEN` as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLOPS_SERVICE_URL=https://app.datarobot.com\n",
      "env: MLOPS_API_TOKEN=YOUR_API_TOKEN\n"
     ]
    }
   ],
   "source": [
    "%env MLOPS_SERVICE_URL=https://app.datarobot.com\n",
    "#PUT Your DataRobot API Key here:\n",
    "%env MLOPS_API_TOKEN=PUT_YOUR_API_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload a training dataset to DataRobot AI Catalog\n",
    "\n",
    "In the UI, you can [import a dataset via the AI catalog](https://app.datarobot.com/docs/data/ai-catalog/catalog.html#add-data).\n",
    "\n",
    "Alternatively, you can use `mlops-cli` from the command line as demonstrated in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# ^^^^ Just to catch mlops-cli commands output to process it programmatically, comment it for cell output \n",
    "# Load the training dataset using mlops-cli, \n",
    "# we are using --json --quiet options here to catch command output as a json to process it programmatically\n",
    "# if you need text output you can use --terse option\n",
    "!mlops-cli dataset upload --input \"data/iris_with_header.csv\" --timeout 600 --json --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"id\": \"641c32d631185440a581d435\"\n",
      "}\n",
      "\n",
      "Training dataset uploaded successfully, TRAINING_DATASET_ID=641c32d631185440a581d435\n"
     ]
    }
   ],
   "source": [
    "# Output of this command will contain uploaded Dataset ID in 'id' field that needs to be used on the next steps:\n",
    "print(cap.stdout)\n",
    "if \"ERROR\" not in cap.stdout: \n",
    "    stdout_json = json.loads(cap.stdout)\n",
    "    print(\"Training dataset uploaded successfully, TRAINING_DATASET_ID=\"+stdout_json['id'])\n",
    "    #Setting TRAINING_DATASET_ID env variable to use it in the next steps:\n",
    "    os.environ[\"TRAINING_DATASET_ID\"] = stdout_json['id']\n",
    "else:\n",
    "    # Print output of mlops-cli in case of error:\n",
    "    print(\"Training dataset uploading failed:\")\n",
    "    print(cap.stdout) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model package\n",
    "\n",
    "In the UI, you can view existing model packages or add a new one by navigating to [**Model Registry > Model Packages**](https://app.datarobot.com/docs/mlops/deployment/registry/reg-create.html#create-model-packages).\n",
    "\n",
    "Alternatively, you can use `mlops-cli` as shown in the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PACKAGE_NAME=\"SageMaker_MLOps_Demo_v2\"\n",
    "\n",
    "#Set model type\n",
    "prediction_type=\"Multiclass\"\n",
    "#Set traget column\n",
    "model_target = \"variety\"\n",
    "#Set traget classes\n",
    "class_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "model_config = {\n",
    "    \"name\": MODEL_PACKAGE_NAME,\n",
    "    \"modelDescription\": {\n",
    "    \"modelName\": \"Iris classification model\",\n",
    "    \"description\": \"Classification on iris dataset\"\n",
    "    },\n",
    "    \"target\": {\n",
    "        \"type\": prediction_type,\n",
    "        \"name\": model_target,\n",
    "        \"classNames\": class_names\n",
    "    }\n",
    "}\n",
    "\n",
    "# write model configuration json to a file:\n",
    "with open(\"demo_model.json\", \"w\") as model_json_file:\n",
    "    model_json_file.write(json.dumps(model_config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# Create model package\n",
    "# we are using --json --quiet options here to catch command output as a json to process it programmatically\n",
    "# if you need text output you can use --terse option\n",
    "# Using Dataset ID from previouse step as a training-dataset-id argument:\n",
    "!mlops-cli model create --json-config \"demo_model.json\" --training-dataset-id $TRAINING_DATASET_ID  --json --quiet\n",
    "# Output of this command will contain json with created model package ID that needs to be used on the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"id\": \"641c332175cd8d976294d58b\"\n",
      "}\n",
      "\n",
      "Model package created successfully, MODEL_PACKAGE_ID=641c332175cd8d976294d58b\n"
     ]
    }
   ],
   "source": [
    "print(cap.stdout) #Just to check mlops-cli command output\n",
    "if \"ERROR\" not in cap.stdout:\n",
    "    #catch Model Package ID corresponding variable:\n",
    "    stdout_json = json.loads(cap.stdout)\n",
    "    print(\"Model package created successfully, MODEL_PACKAGE_ID=\"+stdout_json['id'])\n",
    "    #Setting TRAINING_DATASET_ID env variable to use it in the next steps:\n",
    "    os.environ[\"MODEL_PACKAGE_ID\"] = stdout_json['id']\n",
    "    #set Model Package ID corresponding variable:\n",
    "    model_id=stdout_json['id']\n",
    "else:\n",
    "    # Handle or output of mlops-cli in case of error:\n",
    "    print(\"Model package creation failed:\")\n",
    "    print(cap.stdout) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataRobot prediction environment\n",
    "\n",
    "Models that run on your own infrastructure (outside of DataRobot) may be run in different environments and can have differing deployment permissions and approval processes. \n",
    "To deploy models on external infrastructure, you need create a custom external prediction environment using the UI or the DataRobot API and copying the prediction environment ID.\n",
    "\n",
    "For more information, reference the documentation for [creating external prediction environments](https://app.datarobot.com/docs/mlops/deployment/ext-model-prep/pred-env.html).\n",
    "\n",
    "To create a prediction environment from `mlops-cli` you can use the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a  configuration\n",
    "demo_pe_config = {\n",
    "    \"name\": \"MLOps SageMaker Demo v2\",\n",
    "    \"description\": \"AWS Sagemaker DataRobot MLOps Demo\",\n",
    "    \"platform\": \"aws\",\n",
    "    \"supportedModelFormats\": [\"externalModel\"]\n",
    "}\n",
    "\n",
    "# Write the configuration json to a file\n",
    "with open(\"demo_pe.json\", \"w\") as demo_pe_file:\n",
    "    demo_pe_file.write(json.dumps(demo_pe_config, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Used to catch mlops-cli commands output\n",
    "# Run this only once, or at least clean up after so you don't end up with a lot of deployments\n",
    "!mlops-cli prediction-environment create --json-config \"demo_pe.json\"  --json --quiet\n",
    "# The output of this command will contain a prediction environment ID that is required in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"id\": \"641c337702b02e65c447d3b0\"\n",
      "}\n",
      "\n",
      "Prediction environment created successfully, PREDICTION_ENVIRONMENT_ID=641c337702b02e65c447d3b0\n"
     ]
    }
   ],
   "source": [
    "# The output of this command contains a prediction environment ID that is required in the following cells\n",
    "print(cap.stdout) #Just to check mlops-cli command output\n",
    "if \"ERROR\" not in cap.stdout:\n",
    "    # Used to catch prediction environment corresponding variable:\n",
    "    stdout_json = json.loads(cap.stdout)\n",
    "    print(\"Prediction environment created successfully, PREDICTION_ENVIRONMENT_ID=\"+stdout_json['id'])\n",
    "    # Set the PREDICTION_ENVIRONMENT_ID environment variable to use it in the following cells\n",
    "    os.environ[\"PREDICTION_ENVIRONMENT_ID\"] = stdout_json['id']\n",
    "else:\n",
    "    # Handle or output of mlops-cli in case of error:\n",
    "    print(\"Prediction environment creation failed:\")\n",
    "    print(cap.stdout) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# In the UI, you can create a deployment from a model package under Model Registry -> {model package} -> Deployments.\n",
    "# Set --deployment-label with name that you choose\n",
    "# --model-package-id from previous step\n",
    "# --prediction-environment-id from previous step\n",
    "!mlops-cli model deploy --model-package-id $MODEL_PACKAGE_ID --prediction-environment-id $PREDICTION_ENVIRONMENT_ID --deployment-label \"SageMaker_MLOps_Demo\"  --json --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"id\": \"641c345ccf103feaf4d2e1a4\"\n",
      "}\n",
      "\n",
      "Model deployment created successfully, DEPLOYMENT_ID=641c345ccf103feaf4d2e1a4\n"
     ]
    }
   ],
   "source": [
    "# The output of this command contains a deployment ID that is required in the following cells\n",
    "print(cap.stdout) # Used to check mlops-cli command output\n",
    "if \"ERROR\" not in cap.stdout:\n",
    "    # Used to catch deployment ID corresponding variable:\n",
    "    stdout_json = json.loads(cap.stdout)\n",
    "    print(\"Model deployment created successfully, DEPLOYMENT_ID=\"+stdout_json['id'])\n",
    "    # Set the deployment_id variable to use it in the next steps:\n",
    "    deployment_id = stdout_json['id']\n",
    "else:\n",
    "    # Handle or output of mlops-cli in case of error:\n",
    "    print(\"Model deployment creation failed:\")\n",
    "    print(cap.stdout) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an SQS queue as a spooler channel\n",
    "\n",
    "The MLOps library communicates to the MLOps agent using a spooler. This workflow uses AWS SQS as a spooler channel, more details how to create SQS queue:\n",
    "You can read more about how to [create an SQS queue using the cloud console UI](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/step-create-queue.html) or [by using the AWS CLI](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/sqs/create-queue.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws sqs create-queue --queue-name datarobot-mlops-demo-v2\n",
    "# MLOps spooler channel SQS queue\n",
    "# Put your SQS queue URL here:\n",
    "MLOPS_SQS_QUEUE=\"https://sqs.us-east-1.amazonaws.com/12345678/aws-mlops-blogpost-demo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host your model\n",
    "\n",
    "You can use a trained model to get real time predictions using an HTTP endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model\n",
    "\n",
    "Deploying a model to SageMaker hosting just requires a `deploy` call with the fitted model. This call requires an instance count, instance type, and optional serializer and deserializer functions. These functions are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MLOPS_DEPLOYMENT_ID': '641c345ccf103feaf4d2e1a4', 'MLOPS_MODEL_ID': '641c332175cd8d976294d58b', 'MLOPS_SQS_QUEUE': 'https://sqs.us-east-1.amazonaws.com/293058073847/aws-mlops-blogpost-demo', 'prediction_type': 'Multiclass', 'CLASS_NAMES': '[\"setosa\", \"versicolor\", \"virginica\"]'}\n",
      "-------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "import json\n",
    "\n",
    "# Pass all required environment variables to the SageMaker deployment\n",
    "env_vars={\n",
    "    \"MLOPS_DEPLOYMENT_ID\": deployment_id,\n",
    "    \"MLOPS_MODEL_ID\": model_id,\n",
    "    \"MLOPS_SQS_QUEUE\": MLOPS_SQS_QUEUE,\n",
    "    \"prediction_type\": prediction_type,\n",
    "    \"CLASS_NAMES\": json.dumps(class_names)}\n",
    "\n",
    "print(env_vars)\n",
    "\n",
    "predictor = tree.deploy(1, \"ml.m4.xlarge\", serializer = CSVSerializer(), env=env_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get prediction data\n",
    "\n",
    "In order to make predictions, extract the data used for training to make predictions against it. This is is strictly for demo purposes as it is bad statistical practice. However it is a good demonstration of how the mechanism works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>setosa</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4\n",
       "65  versicolor  5.6  2.9  3.6  1.3\n",
       "8       setosa    5  3.4  1.5  0.2\n",
       "68  versicolor  5.8  2.7  4.1    1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = pd.read_csv(\"data/iris_with_header.csv\", header=None)\n",
    "shape.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4\n",
       "125  6.7  3.3  5.7  2.1\n",
       "86     6  3.4  4.5  1.6\n",
       "29   5.2  3.4  1.4  0.2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the label column in the training set\n",
    "shape.drop(shape.columns[[0]], axis=1, inplace=True)\n",
    "shape.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1    2    3    4\n",
       "40   5.1  3.4  1.5  0.2\n",
       "41     5  3.5  1.3  0.3\n",
       "42   4.5  2.3  1.3  0.3\n",
       "43   4.4  3.2  1.3  0.2\n",
       "44     5  3.5  1.6  0.6\n",
       "45   5.1  3.8  1.9  0.4\n",
       "46   4.8    3  1.4  0.3\n",
       "47   5.1  3.8  1.6  0.2\n",
       "48   4.6  3.2  1.4  0.2\n",
       "49   5.3  3.7  1.5  0.2\n",
       "90   5.5  2.5    4  1.3\n",
       "91   5.5  2.6  4.4  1.2\n",
       "92   6.1    3  4.6  1.4\n",
       "93   5.8  2.6    4  1.2\n",
       "94     5  2.3  3.3    1\n",
       "95   5.6  2.7  4.2  1.3\n",
       "96   5.7    3  4.2  1.2\n",
       "97   5.7  2.9  4.2  1.3\n",
       "98   6.2  2.9  4.3  1.3\n",
       "99   5.1  2.5    3  1.1\n",
       "140  6.9  3.1  5.4  2.1\n",
       "141  6.7  3.1  5.6  2.4\n",
       "142  6.9  3.1  5.1  2.3\n",
       "143  5.8  2.7  5.1  1.9\n",
       "144  6.8  3.2  5.9  2.3\n",
       "145  6.7  3.3  5.7  2.5\n",
       "146  6.7    3  5.2  2.3\n",
       "147  6.3  2.5    5  1.9\n",
       "148  6.5    3  5.2    2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "a = [50 * i for i in range(3)]\n",
    "b = [40 + i for i in range(10)]\n",
    "indices = [i + j for i, j in itertools.product(a, b)]\n",
    "\n",
    "test_data = shape.iloc[indices[:-1]]\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction is as easy as calling `predict` with the predictor you get back from `deploy` and the data you want to make predictions with. The serializers convert the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "print(test_data)\n",
    "out = io.StringIO()\n",
    "pd.DataFrame(test_data).to_csv(out, header=True, index=False)\n",
    "print(predictor.predict(out.getvalue()).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Optional. When you're done with the endpoint, you can clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
